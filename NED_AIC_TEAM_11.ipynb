{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NED AIC TEAM 11.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "6lPfD80YBE1w",
        "frfUIR6_BE1x",
        "bW3_78RcBE1y",
        "HohAFyuRBE11",
        "mQ5lNjIFBE11",
        "pSq0BaLrBE14",
        "gqalu3ZoBE15",
        "9tiKTqLuBE15",
        "QO3ztjBdBE16",
        "V3pPlILoBE14",
        "FrJjAAK7BE16",
        "C8O8f-olBE18",
        "zftnYBDWBE19",
        "ukUzEHesBE19",
        "8Ybi7LbhBE1_",
        "11XSVjYUBE1_",
        "sMnN0HZpBE2A",
        "-mMMX3FjBE2B",
        "HpZxx54sBE2B",
        "wHMJDIXyBE2C",
        "yCi9jhgZ6ALX",
        "LBPswnEZ6sK-",
        "o5372aaS6901",
        "zfL796EU7rH-",
        "kUuF3Kgk8Km7",
        "vOprV9u48ggy",
        "G8jyKDHH9bPn",
        "11EDdJSt95QH",
        "nSilyGZD_Vag",
        "1IEgj3np_0iK"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axysD4QozEgr"
      },
      "source": [
        "#**MOUNTING GOOGLE DRIVE AND SETTING PATH**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN-VOfDqy7Bp"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf3p5smLzPU6"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/Tensorflow/workspace"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSTwHuIjzQz6"
      },
      "source": [
        "import os\n",
        "os.environ['PYTHONPATH'] += '/content/gdrive/MyDrive/Tensorflow/workspace/:/content/gdrive/MyDrive/Tensorflow/workspace/models/:/content/gdrive/MyDrive/Tensorflow/workspace/models/research/:/content/gdrive/MyDrive/Tensorflow/workspace/models/research/slim'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blxLTO-pzYgC"
      },
      "source": [
        "#**INSTALLING RELEVANT LIBRARIES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C51_4LRqzjur"
      },
      "source": [
        "!pip install tensorflow_io\n",
        "!pip install tqdm\n",
        "!pip install pydicom\n",
        "!pip install ensemble-boxes\n",
        "!apt-get install protobuf-compiler python-lxml python-pil\n",
        "!pip install Cython pandas tf-slim lvis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu4TlnxzBE1k"
      },
      "source": [
        "# **DOWNLOADING MODELS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1lxcikIBE1r"
      },
      "source": [
        "!git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KkzKps3BE1r"
      },
      "source": [
        "# **COMPILING PROTO FILES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQDuzSrEBE1s"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/Tensorflow/workspace/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "%cd ..\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_gvPNdiBE1s"
      },
      "source": [
        "# **Installing Coco Api for Evaluating the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUmA4AS-BE1s"
      },
      "source": [
        "!pip install cython \n",
        "!git clone https://github.com/cocodataset/cocoapi.git\n",
        "%cd /content/gdrive/My Drive/Tensorflow/cocoapi/PythonAPI\n",
        "!make\n",
        "%cd ..\n",
        "%cd ..\n",
        "!cp -r cocoapi/PythonAPI/pycocotools models/research/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkvZ9J1IBE1t"
      },
      "source": [
        "# **Installing object detection api**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJRACHQ5BE1t"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/Tensorflow/workspace/models/research\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install .\n",
        "%cd ..\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOKPKvVkBE1u"
      },
      "source": [
        "# **Importing Relevant libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dld5h-LBE1u"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from ensemble_boxes import *\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import pydicom\n",
        "from pydicom.tag import Tag\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.applications import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "from object_detection.utils import label_map_util as map_util\n",
        "from object_detection.utils import visualization_utils as viz_util\n",
        "from object_detection.utils import ops as ops_util\n",
        "from object_detection.protos.string_int_label_map_pb2 import StringIntLabelMap, StringIntLabelMapItem\n",
        "from object_detection.dataset_tools import tf_record_creation_util\n",
        "from object_detection.utils import dataset_util\n",
        "import contextlib2\n",
        "\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util as map_util\n",
        "from object_detection.utils import visualization_utils as viz_util\n",
        "from object_detection.utils import ops as ops_util\n",
        "from object_detection.utils import config_util\n",
        "\n",
        "import requests\n",
        "import tarfile\n",
        "from tqdm.notebook import tqdm\n",
        "from io import BytesIO\n",
        "from shutil import copy2\n",
        "import random\n",
        "\n",
        "\n",
        "from google.protobuf import text_format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lPfD80YBE1w"
      },
      "source": [
        "# **Converting Dicom File to Np Array**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xjc_dR_PBE1w"
      },
      "source": [
        "def read_dicom(path, max_dim):\n",
        "    image_bytes = tf.io.read_file(path)\n",
        "    image = tfio.image.decode_dicom_image(\n",
        "        image_bytes, \n",
        "        dtype = tf.uint16\n",
        "    )\n",
        "    \n",
        "    image = tf.squeeze(image, axis = 0)\n",
        "    \n",
        "    h, w, _ = image.shape\n",
        "    \n",
        "    if max_dim != None:\n",
        "        image = tf.image.resize(\n",
        "            image, \n",
        "            (max_dim, max_dim), \n",
        "            preserve_aspect_ratio = True\n",
        "        )\n",
        "\n",
        "    image = image - tf.reduce_min(image)\n",
        "    image = image / tf.reduce_max(image)\n",
        "    image = tf.cast(image * 255, tf.uint8)\n",
        "    \n",
        "    return image, h, w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXw693KhBE1x"
      },
      "source": [
        "Visualizing how a sample image looks like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bSIC6wBDBE1x"
      },
      "source": [
        "# Read one image to check the loading is OK\n",
        "%matplotlib inline\n",
        "demo_image = \"6d5acf3f8a973a26844d617fffe72998.dicom\"\n",
        "\n",
        "img,h,w = read_dicom(os.path.join(path, \"train\", demo_image),500)\n",
        "print(img.numpy())\n",
        "plt.figure(figsize = (10,10))\n",
        "plt.imshow(tf.squeeze(img), 'gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frfUIR6_BE1x"
      },
      "source": [
        "# **Loading Annotation data in train.csv as a dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLrDJatjBE1y"
      },
      "source": [
        "# Create a dataframe containing the training data\n",
        "csv_path = '/kaggle/input/vinbigdata-chest-xray-abnormalities-detection/train.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bW3_78RcBE1y"
      },
      "source": [
        "# **Visualizing Annotations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hbDNnwHuBE1y"
      },
      "source": [
        "# method to plot images with its annotations\n",
        "def plot_annotations(df_item, path, hide_axis = False):\n",
        "    demo_image=df_item['image_id']+'.dicom'\n",
        "    img,h,w = read_dicom(os.path.join(path,\"train\",demo_image ),None)\n",
        "    img=img.numpy()\n",
        "    # Convert the x-ray image into RGB\n",
        "    img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n",
        "    \n",
        "    if (np.isnan(df_item[\"x_min\"]) and np.isnan(df_item[\"y_min\"])):\n",
        "        return print(\"No detection found!\")\n",
        "    \n",
        "    # Declare coordinates and convert them to integers\n",
        "    x_min = int(df_item[\"x_min\"])\n",
        "    y_min = int(df_item[\"y_min\"])\n",
        "    x_max = int(df_item[\"x_max\"])\n",
        "    y_max = int(df_item[\"y_max\"])\n",
        "\n",
        "    # Create figure\n",
        "    plt.figure(figsize = (10,10))\n",
        "    \n",
        "    # Create rectangle where the annotation is located\n",
        "    image = cv2.rectangle(img=img,rec=(x_min,y_min,x_max-x_min,y_max-y_min), color = (0,255,0),thickness = 10)\n",
        "    \n",
        "    # Add label to the annotation\n",
        "    image = cv2.putText(image, df_item[\"class_name\"], (int(df_item[\"x_min\"]),int(df_item[\"y_min\"])-20), cv2.FONT_HERSHEY_TRIPLEX, 2, (0,0,0), 3)\n",
        "                \n",
        "    # Plot image\n",
        "    plt.imshow(image)\n",
        "    plt.axis(\"Off\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2FZTSFzHBE1z"
      },
      "source": [
        "# method to plot images with its annotations\n",
        "def plot_all_labels(df_item, path):\n",
        "    img,h,w=read_dicom(os.path.join(path,\"train\", \"{}.dicom\".format(df_item.iloc[1][\"image_id\"])),None)\n",
        "    img=img.numpy()\n",
        "    # Convert the x-ray image into RGB\n",
        "    image = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n",
        "    \n",
        "    # Create figure\n",
        "    plt.figure(figsize = (10,10))\n",
        "    plt.title(\"Image ID - {}\".format(df_item.iloc[1][\"image_id\"]))\n",
        "    \n",
        "    for index,item in df_item.iterrows():\n",
        "        \n",
        "        if (np.isnan(item[\"x_min\"]) and np.isnan(item[\"y_min\"])):\n",
        "            continue\n",
        "\n",
        "        # Declare coordinates and convert them to integers\n",
        "        x_min = int(item[\"x_min\"])\n",
        "        y_min = int(item[\"y_min\"])\n",
        "        x_max = int(item[\"x_max\"])\n",
        "        y_max = int(item[\"y_max\"])\n",
        "\n",
        "        # Create rectangle where the annotation is located\n",
        "        image = cv2.rectangle(img=image,rec=(x_min,y_min,x_max-x_min,y_max-y_min), color = (0,255,0),thickness = 10)\n",
        "\n",
        "        # Add label to the annotation\n",
        "        image = cv2.putText(image, item[\"class_name\"], (int(item[\"x_min\"]),int(item[\"y_min\"])), cv2.FONT_HERSHEY_SIMPLEX, fontScale=2, color=(0,0,0), thickness=3)\n",
        "\n",
        "                \n",
        "    # Plot image\n",
        "    plt.imshow(image)\n",
        "    plt.axis(\"Off\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mOXps5wBE10"
      },
      "source": [
        "plot_all_labels(image_annotations, path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HohAFyuRBE11"
      },
      "source": [
        "# **Visualizing and Preprocessing Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ5lNjIFBE11"
      },
      "source": [
        "* ### Exploring distribution of radiologists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "P_9uihBcBE11"
      },
      "source": [
        "temp = df[[\"image_id\", \"rad_id\"]].drop_duplicates().reset_index(drop = True)\n",
        "temp = temp.groupby([\"rad_id\"]).agg(\n",
        "    count = pd.NamedAgg(\"image_id\", \"count\")\n",
        ").reset_index()\n",
        "temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "D4m8FxJCBE1y"
      },
      "source": [
        "# Plot the 3rd dataset item\n",
        "\n",
        "plot_annotations(df.iloc[5],path, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cMSui4BlBE11"
      },
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize = (15, 5))\n",
        "\n",
        "sns.countplot(\n",
        "    df[\"rad_id\"], \n",
        "    palette = \"tab10\", \n",
        "    order = list(temp[\"rad_id\"]), \n",
        "    ax = ax[0]\n",
        ")\n",
        "ax[0].set_title(\"Number of annotations by radiologists\")\n",
        "\n",
        "sns.barplot(\n",
        "    x = \"rad_id\", \n",
        "    y = \"count\", \n",
        "    data = temp, \n",
        "    palette = \"tab10\", \n",
        "    ax = ax[1]\n",
        ")\n",
        "ax[1].set_title(\"Number of x-rays seen by radiologists\")\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RiPTWoUBE12"
      },
      "source": [
        "Radiologists 9, 10 and 8 saw most number of x-rays and made most annotations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVOhvaiuBE12"
      },
      "source": [
        "sns.barplot(\n",
        "    x = \"class_name\", \n",
        "    y = \"count\", \n",
        "    data = temp, \n",
        "    palette = \"tab10\"\n",
        ")\n",
        "plt.xticks(rotation = 90)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irk05Pp8BE13"
      },
      "source": [
        "def CLAHE(image):\n",
        "    clahe = cv2.createCLAHE(\n",
        "        clipLimit = 2., \n",
        "        tileGridSize = (10, 10)\n",
        "    )\n",
        "    \n",
        "    image = clahe.apply(image.numpy()) \n",
        "    image = np.expand_dims(image, axis = 2)\n",
        "    \n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOF3BKaXBE13"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "fig = plt.figure(figsize = (8, 8))\n",
        "\n",
        "axes = fig.add_subplot(1, 2, 1)\n",
        "plt.imshow(tf.squeeze(img), cmap = \"gray\")\n",
        "axes.set_title(\"Original\")\n",
        "\n",
        "axes = fig.add_subplot(1, 2, 2)\n",
        "image = CLAHE(img)\n",
        "plt.imshow(tf.squeeze(img), cmap = \"gray\")\n",
        "axes.set_title(\"Post CLAHE\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSq0BaLrBE14"
      },
      "source": [
        "* ### Incrementing Class ids by 1 as our API requires classes for 1 to n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS69Iv0fBE14"
      },
      "source": [
        "df[\"class_id\"] = df[\"class_id\"] + 1 # Incrementing by 1\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqalu3ZoBE15"
      },
      "source": [
        "* ### 14 unique colors to annotate the abnormalities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WEX7uYwBE15"
      },
      "source": [
        "LABEL_COLORS = [\n",
        "    (230, 25, 75), (60, 180, 75), (255, 225, 25), (0, 130, 200), (245, 130, 48), (145, 30, 180), (70, 240, 240), \n",
        "    (240, 50, 230), (210, 245, 60), (250, 190, 212), (0, 128, 128), (220, 190, 255), (170, 110, 40), (255, 250, 200), \n",
        "]\n",
        "LabelMap[\"colors\"] = LABEL_COLORS\n",
        "LabelMap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tiKTqLuBE15"
      },
      "source": [
        "* ### Label map files have the extention .pbtxt so here we are saving LabelMap as .pbtxt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16myz_r9BE15"
      },
      "source": [
        "def save_mapping(LabelMap):\n",
        "    msg = StringIntLabelMap()\n",
        "    \n",
        "    for i, row in LabelMap.iterrows():\n",
        "        msg.item.append(StringIntLabelMapItem(id = row[\"class_id\"], name = row[\"class_name\"]))\n",
        "    \n",
        "    text = str(text_format.MessageToBytes(msg, as_utf8 = True), 'utf-8')\n",
        "    \n",
        "    f = open(\"LabelMap.pbtxt\", \"w\")\n",
        "    f.write(text)\n",
        "    f.close()\n",
        "    \n",
        "save_mapping(LabelMap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO3ztjBdBE16"
      },
      "source": [
        "* ### Removing Examples with No Findings as it will not be used in training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7PLr1bvBE16"
      },
      "source": [
        "# Remove examples with no findings (won't be used for training)\n",
        "df = df.dropna().reset_index(drop = True)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3pPlILoBE14"
      },
      "source": [
        "* ### TensorFlow requires a label map, which namely maps each of the used labels to an integer values.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAJua5JQBE14"
      },
      "source": [
        "LabelMap = df.loc[df[\"class_name\"] != \"No finding\", [\"class_name\", \"class_id\"]] # Removing the examples with no finding\n",
        "LabelMap = LabelMap.drop_duplicates().reset_index(drop = True)\n",
        "LabelMap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrJjAAK7BE16"
      },
      "source": [
        "* ### Changing Data Types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ5UY7vqBE16"
      },
      "source": [
        "df = df.astype({\n",
        "    \"x_min\": int, \n",
        "    \"y_min\": int, \n",
        "    \"x_max\": int, \n",
        "    \"y_max\": int,\n",
        "    \"class_id\": str\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAyz83FeBE17"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKWbLvppBE17"
      },
      "source": [
        "def plot_boxes(image, data, title):    \n",
        "    img = cv2.cvtColor(image.numpy(), cv2.COLOR_GRAY2RGB)\n",
        "    \n",
        "    for i, row in data.iterrows():\n",
        "    \n",
        "        x1, y1 = row[\"x_min\"], row[\"y_min\"]\n",
        "        x2, y2 = row[\"x_max\"], row[\"y_max\"]\n",
        "    \n",
        "        cv2.rectangle(\n",
        "            img,\n",
        "            pt1 = (x1, y1),\n",
        "            pt2 = (x2, y2),\n",
        "            color=row['colors'],\n",
        "            thickness = 2\n",
        "        )\n",
        "    \n",
        "        cv2.putText(\n",
        "            img, \n",
        "            row[\"class_name\"], \n",
        "            (x1, y1-5), \n",
        "            cv2.FONT_HERSHEY_SIMPLEX, \n",
        "            0.5, \n",
        "            row['colors'], \n",
        "            1\n",
        "        )\n",
        "\n",
        "    plt.figure(figsize = (8, 8))\n",
        "    plt.imshow(img) \n",
        "    plt.title(title)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfdyD2U4BE17"
      },
      "source": [
        "# Selecting a particular radiologist\n",
        "demo_rad = \"R9\"\n",
        "\n",
        "# Preprocessing metadata to suit needs\n",
        "data = df.loc[\n",
        "    (df[\"image_id\"] == demo_image[:-6]) & (df[\"rad_id\"] == demo_rad),\n",
        "    [\"class_name\", \"x_min\", \"y_min\", \"x_max\", \"y_max\"]\n",
        "]\n",
        "\n",
        "H, W, _ = img.shape\n",
        "data[[\"x_min\", \"x_max\"]] = (data[[\"x_min\", \"x_max\"]]* W/w).astype(int)\n",
        "data[[\"y_min\", \"y_max\"]] = (data[[\"y_min\", \"y_max\"]]* H/h).astype(int)\n",
        "\n",
        "data = pd.merge(data, LabelMap)\n",
        "\n",
        "# Plotting annotation by radiologist\n",
        "plot_boxes(img, data, \"Labels for \" + demo_image + \" by \" + demo_rad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlbsjuiEBE18"
      },
      "source": [
        "# Preprocessing metadata to suit needs\n",
        "data = df.loc[\n",
        "    (df[\"image_id\"] == demo_image[:-6]),\n",
        "    [\"class_name\", \"x_min\", \"y_min\", \"x_max\", \"y_max\"]\n",
        "]\n",
        "\n",
        "H, W, _ = img.shape\n",
        "data[[\"x_min\", \"x_max\"]] = (data[[\"x_min\", \"x_max\"]]* W/w).astype(int)\n",
        "data[[\"y_min\", \"y_max\"]] = (data[[\"y_min\", \"y_max\"]]* H/h).astype(int)\n",
        "\n",
        "data = pd.merge(data, LabelMap)\n",
        "\n",
        "# Plotting annotation by all radiologists\n",
        "plot_boxes(img, data, \"Labels for \" + demo_image + \" by all radiologists\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C57vrp6n38cZ"
      },
      "source": [
        "# Preprocessing metadata to suit needs\n",
        "data = df.loc[\n",
        "    (df[\"image_id\"] == demo_image[:-6]),\n",
        "    [\"class_name\", \"x_min\", \"y_min\", \"x_max\", \"y_max\"]\n",
        "]\n",
        "\n",
        "H, W, _ = img.shape\n",
        "data[[\"x_min\", \"x_max\"]] = (data[[\"x_min\", \"x_max\"]]* W/w).astype(int)\n",
        "data[[\"y_min\", \"y_max\"]] = (data[[\"y_min\", \"y_max\"]]* H/h).astype(int)\n",
        "\n",
        "data = pd.merge(data, LabelMap)\n",
        "\n",
        "# Plotting annotation by all radiologists\n",
        "plot_boxes(img, data, \"Labels for \" + demo_image + \" by all radiologists\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjh80oFY38cb"
      },
      "source": [
        "print(w)\n",
        "print(W)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29NZ_wJlBE18"
      },
      "source": [
        "print(w)\n",
        "print(W)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Z7I0DeaBE18"
      },
      "source": [
        "We need not train our model on multiple annotations of the same abnormality. We shall use a technique called Weighted Boxes Fusion (WBF) to provide us with the best annotation. This will definitely reduce the metadata size by a lot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8O8f-olBE18"
      },
      "source": [
        "* ### Preprocessing as needed for Weighted Boxes Fusion (WBF)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDc0UzmmBE18"
      },
      "source": [
        "data = df.loc[\n",
        "    (df[\"image_id\"] == demo_image[:-6]),\n",
        "    [\"class_name\", \"x_min\", \"y_min\", \"x_max\", \"y_max\"]\n",
        "]\n",
        "\n",
        "data[[\"x_min\", \"x_max\"]] = data[[\"x_min\", \"x_max\"]]/w\n",
        "data[[\"y_min\", \"y_max\"]] = data[[\"y_min\", \"y_max\"]]/h\n",
        "\n",
        "data = pd.merge(data, LabelMap)\n",
        "\n",
        "boxes_list = data[[\"x_min\", \"y_min\", \"x_max\", \"y_max\"]].values.tolist()\n",
        "scores_list = [1]*len(boxes_list)\n",
        "labels_list = list(data[\"class_id\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zftnYBDWBE19"
      },
      "source": [
        "* ### Applying Weighted Box Fusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEy3nGLZBE19"
      },
      "source": [
        "boxes, _, labels = weighted_boxes_fusion(\n",
        "    boxes_list = [boxes_list],\n",
        "    scores_list = [scores_list],\n",
        "    labels_list = [labels_list],\n",
        "    weights = None, \n",
        "    iou_thr = 0.3, \n",
        "    skip_box_thr = 0.0001\n",
        ")\n",
        "\n",
        "data = pd.DataFrame(boxes, columns = [\"x_min\", \"y_min\", \"x_max\", \"y_max\"])\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukUzEHesBE19"
      },
      "source": [
        "* ### Postprocessing after applying WBF "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3pykyF1BE19"
      },
      "source": [
        "data = pd.DataFrame(boxes, columns = [\"x_min\", \"y_min\", \"x_max\", \"y_max\"])\n",
        "\n",
        "H, W,_= img.shape\n",
        "data[[\"x_min\", \"x_max\"]] = (data[[\"x_min\", \"x_max\"]]* W).astype(int)\n",
        "data[[\"y_min\", \"y_max\"]] = (data[[\"y_min\", \"y_max\"]]* H).astype(int)\n",
        "\n",
        "data[\"class_id\"] = labels.astype(int)\n",
        "\n",
        "data = pd.merge(data,LabelMap)\n",
        "\n",
        "# Plotting annotation by all radiologists\n",
        "plot_boxes(img, data, \"Labels for \" + demo_image + \" post WBF\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbzekQ2aBE1-"
      },
      "source": [
        "We have eliminated multiple annotations for the same abnormality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ7LQtZgBE1-"
      },
      "source": [
        "# Dropping rad_id as it is not required for training\n",
        "df = df.drop(columns = [\"rad_id\"])\n",
        "\n",
        "# Obtaining set of x-rays with at least one finding\n",
        "xrays = set(df[\"image_id\"]) # Only 4394 x-rays, not 15000. Roughly 30% of the x-rays remain."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MJ4CmkqBE1-"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0QR4gSmBE1-"
      },
      "source": [
        "dimensions = []\n",
        "for i, xray in tqdm(enumerate(xrays)):\n",
        "    ds = pydicom.dcmread(\n",
        "        os.path.join(path, \"train\", xray + \".dicom\"), \n",
        "        specific_tags = [\n",
        "            Tag(\"0028\", \"0010\"), # Tag for Rows (Height)\n",
        "            Tag(\"0028\", \"0011\")  # Tag for Columns (Width)\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    dimensions.append([xray, ds.Rows, ds.Columns])\n",
        "\n",
        "dimensions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QUVO2i3BE1_"
      },
      "source": [
        "dimensions = pd.DataFrame(dimensions, columns = [\"image_id\", \"height\", \"width\"])\n",
        "df = pd.merge(dimensions, df)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ybi7LbhBE1_"
      },
      "source": [
        "* ### Normalizing coordinates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwxkAF6QBE1_"
      },
      "source": [
        "df[\"x_min\"], df[\"x_max\"] = df[\"x_min\"]/df[\"width\"], df[\"x_max\"]/df[\"width\"]\n",
        "df[\"y_min\"], df[\"y_max\"] = df[\"y_min\"]/df[\"height\"], df[\"y_max\"]/df[\"height\"]\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsRhTrDb4ccV"
      },
      "source": [
        "df[\"x_min\"], df[\"x_max\"] = df[\"x_min\"]/df[\"width\"], df[\"x_max\"]/df[\"width\"]\n",
        "df[\"y_min\"], df[\"y_max\"] = df[\"y_min\"]/df[\"height\"], df[\"y_max\"]/df[\"height\"]\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11XSVjYUBE1_"
      },
      "source": [
        "* ### Applying WBF on complete dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9PRaIa1BE1_"
      },
      "source": [
        "# Before applying WBF we had 36096 rows\n",
        "df_list = []\n",
        "for i, xray in tqdm(enumerate(xrays)):\n",
        "    data = df[df[\"image_id\"] == xray]\n",
        "\n",
        "    boxes_list = data[[\"x_min\", \"y_min\", \"x_max\", \"y_max\"]].values.tolist()\n",
        "    scores_list = [1]*len(boxes_list)\n",
        "    labels_list = list(data[\"class_id\"])\n",
        "\n",
        "    # Applying WBF\n",
        "    boxes, _, labels = weighted_boxes_fusion(\n",
        "        boxes_list = [boxes_list],\n",
        "        scores_list = [scores_list],\n",
        "        labels_list = [labels_list],\n",
        "        weights = None, \n",
        "        iou_thr = 0.3, \n",
        "        skip_box_thr = 0.0001\n",
        "    )\n",
        "    \n",
        "    data = pd.DataFrame(boxes, columns = [\"x_min\", \"y_min\", \"x_max\", \"y_max\"]) \n",
        "    # Leaving the coordinates normalized since the API expects them to be so. \n",
        "    \n",
        "    data[\"class_id\"] = labels.astype(int)\n",
        "    \n",
        "    data[\"image_id\"] = xray \n",
        "    \n",
        "    df_list.append(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uMsXYZNBE2A"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVEhwpB-BE2A"
      },
      "source": [
        "df = pd.concat(df_list) # After applying WBF we have 21836 rows\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpe7-yK9BE2A"
      },
      "source": [
        "df = pd.merge(df, LabelMap)\n",
        "df = df.drop(columns=['colors'])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMnN0HZpBE2A"
      },
      "source": [
        "* ### Stratified K-Fold Sharding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo0KnjIPBE2B"
      },
      "source": [
        "num_shards = 25\n",
        "\n",
        "skf = StratifiedKFold(\n",
        "    n_splits = num_shards, \n",
        "    shuffle = True, \n",
        "    random_state = 0\n",
        ")\n",
        "\n",
        "df_folds = df[['image_id']].copy()\n",
        "\n",
        "df_folds.loc[:, 'bbox_count'] = 1\n",
        "df_folds = df_folds.groupby('image_id').count()   # Number of bounding boxes in the image\n",
        "df_folds.loc[:, 'object_count'] = df.groupby('image_id')['class_id'].nunique() # Number of classes in the image\n",
        "df_folds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mMMX3FjBE2B"
      },
      "source": [
        "* ### Preparing stratify groups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibwHBwUyBE2B"
      },
      "source": [
        "\n",
        "df_folds.loc[:, 'stratify_group'] = np.char.add(\n",
        "    df_folds['object_count'].values.astype(str),\n",
        "    df_folds['bbox_count'].apply(lambda x: f'_{x // 15}').values.astype(str)\n",
        ")\n",
        "df_folds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpZxx54sBE2B"
      },
      "source": [
        "* ### Determining which fold the x-ray will fall in"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odHy7XWHBE2B"
      },
      "source": [
        "df_folds.loc[:, 'fold'] = 0\n",
        "skf_split = skf.split(\n",
        "    X = df_folds.index, \n",
        "    y = df_folds['stratify_group']\n",
        ")\n",
        "\n",
        "for fold_number, (train_index, val_index) in enumerate(skf_split):\n",
        "    df_folds.loc[df_folds.iloc[val_index].index, 'fold'] = fold_number\n",
        "    \n",
        "df_folds.reset_index(inplace = True)\n",
        "\n",
        "df_folds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Rj6HolhBE2C"
      },
      "source": [
        "df = pd.merge(df, df_folds)\n",
        "\n",
        "temp = df.groupby([\"fold\", \"class_name\"]).agg(\n",
        "    count = pd.NamedAgg(\"class_name\", \"count\")\n",
        ").reset_index()\n",
        "\n",
        "temp = temp.pivot_table(\n",
        "    index = \"class_name\",\n",
        "    columns = \"fold\",\n",
        "    values = \"count\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIinwbI3BE2C"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHMJDIXyBE2C"
      },
      "source": [
        "# **Converting our annotations into the so called TFRecord format.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZIeKELLBE2C"
      },
      "source": [
        "def create_tf_record(img_path, max_dim, img_df):\n",
        "    \n",
        "    filename = img_path.split(\"/\")[-1].encode()\n",
        "    source_id = img_path.encode()\n",
        "    \n",
        "    # Preprocess image \n",
        "    img, _, _ = read_dicom(img_path, max_dim)\n",
        "    height, width, _ = img.shape\n",
        "    img = CLAHE(img)\n",
        "    \n",
        "    # Encode as JPEG (Lossy compression)\n",
        "    img = tf.io.encode_jpeg(\n",
        "        img, \n",
        "        quality = 100, \n",
        "        format = 'grayscale'\n",
        "    )\n",
        "    \n",
        "    img_bytes = img.numpy()\n",
        "    \n",
        "    img_format = b'jpeg'\n",
        "\n",
        "    xmin_list = list(img_df[\"x_min\"])\n",
        "    xmax_list = list(img_df[\"x_max\"])\n",
        "    ymin_list = list(img_df[\"y_min\"])\n",
        "    ymax_list = list(img_df[\"y_max\"])\n",
        "    \n",
        "    class_name_list = list(img_df[\"class_name\"])\n",
        "    class_name_list = [c.encode() for c in class_name_list]\n",
        "    \n",
        "    class_id_list = list(img_df[\"class_id\"])\n",
        "    \n",
        "    # Creating TFRecord\n",
        "    tf_record = tf.train.Example(\n",
        "        features = tf.train.Features(\n",
        "            feature = {\n",
        "                'image/height': dataset_util.int64_feature(height),\n",
        "                'image/width': dataset_util.int64_feature(width),\n",
        "                'image/filename': dataset_util.bytes_feature(filename),\n",
        "                'image/source_id': dataset_util.bytes_feature(source_id),\n",
        "                'image/encoded': dataset_util.bytes_feature(img_bytes),\n",
        "                'image/format': dataset_util.bytes_feature(img_format),\n",
        "                'image/object/bbox/xmin': dataset_util.float_list_feature(xmin_list),\n",
        "                'image/object/bbox/xmax': dataset_util.float_list_feature(xmax_list),\n",
        "                'image/object/bbox/ymin': dataset_util.float_list_feature(ymin_list),\n",
        "                'image/object/bbox/ymax': dataset_util.float_list_feature(ymax_list),\n",
        "                'image/object/class/text': dataset_util.bytes_list_feature(class_name_list),\n",
        "                'image/object/class/label': dataset_util.int64_list_feature(class_id_list),\n",
        "            }\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    return tf_record"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4H0yGnzBE2D"
      },
      "source": [
        "annot_path = \"workspace/annotations\" \n",
        "os.makedirs(annot_path, exist_ok = True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQyzHNwTBE2D"
      },
      "source": [
        "img_cnt = np.zeros(num_shards, dtype = int)\n",
        "\n",
        "max_dim=500\n",
        "\n",
        "with contextlib2.ExitStack() as tf_record_close_stack:\n",
        "    output_tfrecords = tf_record_creation_util.open_sharded_output_tfrecords(\n",
        "        tf_record_close_stack, \n",
        "        annot_path, \n",
        "        num_shards\n",
        "    )\n",
        "    \n",
        "    for i in tqdm(range(num_shards)):\n",
        "        df_shard = df[df[\"fold\"] == i]\n",
        "        xrays = set(df_shard[\"image_id\"])\n",
        "        \n",
        "        for xray in xrays:\n",
        "            df_image = df_shard[df_shard[\"image_id\"] == xray]\n",
        "            \n",
        "            img_path = os.path.join(path, \"train\", xray + \".dicom\")\n",
        "            tf_record = create_tf_record(img_path, max_dim, df_image)\n",
        "            output_tfrecords[i].write(tf_record.SerializeToString())\n",
        "            \n",
        "            img_cnt[i] += 1\n",
        "\n",
        "print(\"Converted {} images\".format(np.sum(img_cnt)))\n",
        "print(\"Images per shard: {}\".format(img_cnt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfHgcutwBE2D"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEG0kxUnBE2D"
      },
      "source": [
        "# Save dataframe\n",
        "df.to_csv(\"data.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCi9jhgZ6ALX"
      },
      "source": [
        "#**Training and Validating**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoIMg3TPBE2E"
      },
      "source": [
        "from shutil import copy2\n",
        "# Creating workspace\n",
        "os.makedirs(\"/content/gdrive/MyDrive/Tensorflow/workspace/pretrained_models\", exist_ok = True)\n",
        "os.makedirs(\"/content/gdrive/MyDrive/Tensorflow/workspace/models\", exist_ok = True)\n",
        "os.makedirs(\"/content/gdrive/MyDrive/Tensorflow/workspace/exported_models\", exist_ok = True)\n",
        "copy2(\"/content/gdrive/MyDrive/Tensorflow/workspace/models/research/object_detection/model_main_tf2.py\", \"/content/gdrive/MyDrive/Tensorflow/workspace\")\n",
        "copy2(\"/content/gdrive/MyDrive/Tensorflow/workspace/models/research/object_detection/exporter_main_v2.py\", \"/content/gdrive/MyDrive/Tensorflow/workspace\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNwIKFnbBE2E"
      },
      "source": [
        "path_annot=\"/content/gdrive/MyDrive/Tensorflow/workspace/annotations\"\n",
        "raw_dataset = tf.data.TFRecordDataset(os.path.join(path_annot, \"annotations-00000-of-00025\"))\n",
        "\n",
        "for raw_record in raw_dataset.take(1): # Select one shard from the TFRecords dataset\n",
        "    example = tf.train.Example()\n",
        "    example.ParseFromString(raw_record.numpy())\n",
        "print(example)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK-PYU6YBE2E"
      },
      "source": [
        "def GetData(example):\n",
        "    xmin = example.features.feature['image/object/bbox/xmin'].float_list.value\n",
        "    xmax = example.features.feature['image/object/bbox/xmax'].float_list.value\n",
        "    ymin = example.features.feature['image/object/bbox/ymin'].float_list.value\n",
        "    ymax = example.features.feature['image/object/bbox/ymax'].float_list.value\n",
        "\n",
        "    class_name_list = example.features.feature['image/object/class/text'].bytes_list.value\n",
        "    class_name_list = [c.decode() for c in class_name_list]\n",
        "\n",
        "    class_id_list = example.features.feature['image/object/class/label'].int64_list.value\n",
        "\n",
        "    data = pd.DataFrame(\n",
        "        zip(xmin, ymin, xmax, ymax, class_name_list, class_id_list), \n",
        "        columns = [\"x_min\", \"y_min\", \"x_max\", \"y_max\", \"class_name\", \"class_id\"]\n",
        "    )\n",
        "    print(data)\n",
        "\n",
        "    height = example.features.feature['image/height'].int64_list.value[0]\n",
        "    width = example.features.feature['image/width'].int64_list.value[0]\n",
        "\n",
        "    data[[\"x_min\", \"x_max\"]] = (data[[\"x_min\", \"x_max\"]]*width).astype(int)\n",
        "    data[[\"y_min\", \"y_max\"]] = (data[[\"y_min\", \"y_max\"]]*height).astype(int)\n",
        "\n",
        "    LABEL_COLORS = [\n",
        "        (230, 25, 75), (60, 180, 75), (255, 225, 25), (0, 130, 200), (245, 130, 48), (145, 30, 180), (70, 240, 240), \n",
        "        (240, 50, 230), (210, 245, 60), (250, 190, 212), (0, 128, 128), (220, 190, 255), (170, 110, 40), (255, 250, 200) \n",
        "    ]\n",
        "    data[\"colors\"] = data[\"class_id\"].apply(lambda x: LABEL_COLORS[x-1])\n",
        "    \n",
        "    \n",
        "    img_encoded = example.features.feature['image/encoded'].bytes_list.value[0]\n",
        "    image = tf.io.decode_jpeg(img_encoded)\n",
        "    \n",
        "    return data, image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYb8t5fEBE2E"
      },
      "source": [
        "data, image = GetData(example)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Exh3nZdOYBRE"
      },
      "source": [
        "def plot_boxes(image, data, title):    \n",
        "    img = cv2.cvtColor(image.numpy(), cv2.COLOR_GRAY2RGB)\n",
        "    \n",
        "    for i, row in data.iterrows():\n",
        "    \n",
        "        x1, y1 = row[\"x_min\"], row[\"y_min\"]\n",
        "        x2, y2 = row[\"x_max\"], row[\"y_max\"]\n",
        "    \n",
        "        cv2.rectangle(\n",
        "            img,\n",
        "            pt1 = (x1, y1),\n",
        "            pt2 = (x2, y2),\n",
        "            color=row['colors'],\n",
        "            thickness = 2\n",
        "        )\n",
        "    \n",
        "        cv2.putText(\n",
        "            img, \n",
        "            row[\"class_name\"], \n",
        "            (x1, y1-5), \n",
        "            cv2.FONT_HERSHEY_SIMPLEX, \n",
        "            0.5, \n",
        "            row['colors'], \n",
        "            1\n",
        "        )\n",
        "    %matplotlib inline\n",
        "    plt.figure(figsize = (8, 8))\n",
        "    plt.imshow(img)\n",
        "    plt.title(title)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPhGweYiBE2F"
      },
      "source": [
        "plot_boxes(image, data, \"Image extracted from TFRecord\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBPswnEZ6sK-"
      },
      "source": [
        "#**Setting things for Efficientdet D1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gatniF4A6zYf"
      },
      "source": [
        "path = \"/content/gdrive/MyDrive/Tensorflow/workspace/pretrained_models\"\n",
        "fname = \"pipeline.config\"\n",
        "model_name = \"efficientdet_d1_coco17_tpu-32-300\"\n",
        "src = \"/content/gdrive/MyDrive/Tensorflow/workspace/pretrained_models/efficientdet_d1_coco17_tpu-32/pipeline.config\"\n",
        "dst = \"/content/gdrive/MyDrive/Tensorflow/workspace/models/efficientdet_d1_coco17_tpu-32-300/\"\n",
        "path_label = \"/content/gdrive/MyDrive/Tensorflow/workspace/LabelMap.pbtxt\" \n",
        "annot = \"/content/gdrive/MyDrive/Tensorflow/workspace/annotations\"\n",
        "fpath = os.path.join(\"/content/gdrive/MyDrive/Tensorflow/workspace/models/efficientdet_d1_coco17_tpu-32-300\", fname)\n",
        "LabelMap = map_util.create_category_index_from_labelmap(\n",
        "    path_label, \n",
        "    use_display_name = True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5372aaS6901"
      },
      "source": [
        "#**Downloading Efficientdet D1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cALRGy8l6856"
      },
      "source": [
        "# Download EfficientDet from Model Zoo\n",
        "url = \"http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d1_coco17_tpu-32.tar.gz\"\n",
        "\n",
        "r = requests.get(url)\n",
        "\n",
        "# Extract model\n",
        "thetarfile = tarfile.open(\n",
        "    fileobj = BytesIO(r.content), \n",
        "    mode = \"r|gz\"\n",
        ")\n",
        "\n",
        "# Save model\n",
        "thetarfile.extractall(path = path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXq6h9MjBE2F"
      },
      "source": [
        "# Moving pipeline.config file to models directory\n",
        "\n",
        "os.makedirs(dst, exist_ok = True)\n",
        "\n",
        "copy2(src, dst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq_17N-uBE2G"
      },
      "source": [
        "len(LabelMap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITqCbLmQBE2G"
      },
      "source": [
        "os.makedirs(annot, exist_ok = True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJKozkGhBE2G"
      },
      "source": [
        "import random\n",
        "annot_dir = os.listdir(annot)\n",
        "random.Random(5).shuffle(annot_dir)\n",
        "print(len(annot_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MY7EI00BE2H"
      },
      "source": [
        "train_data = annot_dir[:-2]\n",
        "train_data = [os.path.join(annot, d) for d in train_data]\n",
        "\n",
        "valid_data = annot_dir[-2:]\n",
        "valid_data = [os.path.join(annot, d) for d in valid_data]\n",
        "\n",
        "#test_data = annot_dir[-2:]\n",
        "#test_data = [os.path.join(annot, d) for d in test_data]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dnzmn2aOBE2H"
      },
      "source": [
        "len(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL_ORfL3BE2H"
      },
      "source": [
        "valid_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfL796EU7rH-"
      },
      "source": [
        "#**Editing Pipeline.config file of Efficientdet d1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNdRKPUKBE2I"
      },
      "source": [
        "# Making recommended changes\n",
        "config_dic = config_util.get_configs_from_pipeline_file(fpath)\n",
        "\n",
        "config_dic[\"model\"].ssd.num_classes = len(LabelMap)\n",
        "config_dic[\"model\"].ssd.image_resizer.keep_aspect_ratio_resizer.min_dimension = 300\n",
        "config_dic[\"model\"].ssd.image_resizer.keep_aspect_ratio_resizer.max_dimension = 512\n",
        "\n",
        "config_dic[\"train_config\"].batch_size = 8\n",
        "config_dic[\"train_config\"].fine_tune_checkpoint = os.path.join(\"/content/gdrive/MyDrive/Tensorflow/workspace/pretrained_models\",\"efficientdet_d1_coco17_tpu-32\", \"checkpoint/ckpt-0\")\n",
        "config_dic[\"train_config\"].fine_tune_checkpoint_type = \"detection\"\n",
        "config_dic[\"train_config\"].use_bfloat16 = False # Set to True if training on a TPU\n",
        "config_dic[\"train_config\"].num_steps = 5000\n",
        "\n",
        "config_dic[\"train_input_config\"].label_map_path = path_label\n",
        "config_dic[\"train_input_config\"].tf_record_input_reader.input_path[:] = train_data\n",
        "\n",
        "config_dic[\"eval_input_configs\"][0].label_map_path = path_label\n",
        "config_dic[\"eval_input_configs\"][0].tf_record_input_reader.input_path[:] = valid_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jdk8uVK1qixC"
      },
      "source": [
        "config = config_util.create_pipeline_proto_from_configs(config_dic)\n",
        "config_util.save_pipeline_config(config, \"/content/gdrive/MyDrive/Tensorflow/workspace/models/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8-300-10000/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUuF3Kgk8Km7"
      },
      "source": [
        "#**Training the Model on Efficientdet d1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgniG4pU8cIy"
      },
      "source": [
        "!python /content/gdrive/MyDrive/Tensorflow/workspace/model_main_tf2.py --model_dir=$dst --pipeline_config_path=$fpath"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOprV9u48ggy"
      },
      "source": [
        "#**Exporting the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GNzhyP38jFU"
      },
      "source": [
        "!python /content/gdrive/MyDrive/Tensorflow/workspace/exporter_main_v2.py --input_type=image_tensor --pipeline_config_path=$fpath --trained_checkpoint_dir=$dst --output_directory=/content/gdrive/MyDrive/Tensorflow/workspace/exported_models/$model_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8jyKDHH9bPn"
      },
      "source": [
        "#**Setting things for Faster-RCNN Incepetion Resnet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQADXbHa90wo"
      },
      "source": [
        "path = \"/content/gdrive/MyDrive/Tensorflow/workspace/pretrained_models\"\n",
        "fname = \"pipeline.config\"\n",
        "model_name = \"faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8\"\n",
        "src = \"/content/gdrive/MyDrive/Tensorflow/workspace/pretrained_models/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8/pipeline.config\"\n",
        "dst = \"/content/gdrive/MyDrive/Tensorflow/workspace/models/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8/\"\n",
        "path_label = \"/content/gdrive/MyDrive/Tensorflow/workspace/LabelMap.pbtxt\" \n",
        "annot = \"/content/gdrive/MyDrive/Tensorflow/workspace/annotations\"\n",
        "fpath = os.path.join(\"/content/gdrive/MyDrive/Tensorflow/workspace/models/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8\", fname)\n",
        "LabelMap = map_util.create_category_index_from_labelmap(\n",
        "    path_label, \n",
        "    use_display_name = True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11EDdJSt95QH"
      },
      "source": [
        "#**Downloading Faster RCNN Inception Resnet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9etk0O__KhW"
      },
      "source": [
        "url = \"http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8.tar.gz\"\n",
        "\n",
        "r = requests.get(url)\n",
        "\n",
        "# Extract model\n",
        "thetarfile = tarfile.open(\n",
        "    fileobj = BytesIO(r.content), \n",
        "    mode = \"r|gz\"\n",
        ")\n",
        "\n",
        "# Save model\n",
        "thetarfile.extractall(path = path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln4m_LBH_Sfl"
      },
      "source": [
        "# Moving pipeline.config file to models directory\n",
        "\n",
        "os.makedirs(dst, exist_ok = True)\n",
        "\n",
        "copy2(src, dst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSilyGZD_Vag"
      },
      "source": [
        "#**Editing pipeline.config for Faster RCNN Inception Resnet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qudp8kAq_mO8"
      },
      "source": [
        "# Making recommended changes\n",
        "config_dic = config_util.get_configs_from_pipeline_file(fpath)\n",
        "\n",
        "config_dic[\"model\"].faster_rcnn.num_classes = len(LabelMap)\n",
        "config_dic[\"model\"].faster_rcnn.image_resizer.keep_aspect_ratio_resizer.min_dimension = 100\n",
        "config_dic[\"model\"].faster_rcnn.image_resizer.keep_aspect_ratio_resizer.max_dimension = 512\n",
        "config_dic[\"model\"].faster_rcnn.image_resizer.keep_aspect_ratio_resizer.pad_to_max_dimension = False \n",
        "\n",
        "\n",
        "config_dic[\"train_config\"].batch_size = 8\n",
        "config_dic[\"train_config\"].fine_tune_checkpoint = os.path.join(\"/content/gdrive/MyDrive/Tensorflow/workspace/pretrained_models\", model_name, \"checkpoint/ckpt-0\")\n",
        "config_dic[\"train_config\"].fine_tune_checkpoint_type = \"detection\"\n",
        "config_dic[\"train_config\"].use_bfloat16 = False # Set to True if training on a TPU\n",
        "config_dic[\"train_config\"].num_steps = 15000\n",
        "\n",
        "config_dic[\"train_input_config\"].label_map_path = path_label\n",
        "config_dic[\"train_input_config\"].tf_record_input_reader.input_path[:] = train_data\n",
        "\n",
        "config_dic[\"eval_input_configs\"][0].label_map_path = path_label\n",
        "config_dic[\"eval_input_configs\"][0].tf_record_input_reader.input_path[:] = valid_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXIGNtEg_0h3"
      },
      "source": [
        "config = config_util.create_pipeline_proto_from_configs(config_dic)\n",
        "config_util.save_pipeline_config(config, \"/content/gdrive/MyDrive/Tensorflow/workspace/models/faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8-300-10000/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IEgj3np_0iK"
      },
      "source": [
        "#**Training the Model on Efficientdet d1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2K_QqArw_0iK"
      },
      "source": [
        "!python /content/gdrive/MyDrive/Tensorflow/workspace/model_main_tf2.py --model_dir=$dst --pipeline_config_path=$fpath"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i85MbaGg_0iL"
      },
      "source": [
        "#**Exporting the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFR9HL-y_0iL"
      },
      "source": [
        "!python /content/gdrive/MyDrive/Tensorflow/workspace/exporter_main_v2.py --input_type=image_tensor --pipeline_config_path=$fpath --trained_checkpoint_dir=$dst --output_directory=/content/gdrive/MyDrive/Tensorflow/workspace/exported_models/$model_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsyNYPr1LnUd"
      },
      "source": [
        "#**Creating TF Record for Test Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_Aau84JLmWX"
      },
      "source": [
        "def create_tf_record_test(img_path, max_dim):\n",
        "    \n",
        "    filename = img_path.split(\"/\")[-1].encode()\n",
        "    source_id = img_path.encode()\n",
        "    \n",
        "    # Preprocess image \n",
        "    img, h, w = read_dicom(img_path, max_dim)\n",
        "    #height, width, _ = img.shape\n",
        "    img = CLAHE(img)\n",
        "    \n",
        "    # Encode as JPEG (Lossy compression)\n",
        "    img = tf.io.encode_jpeg(\n",
        "        img, \n",
        "        quality = 100, \n",
        "        format = 'grayscale'\n",
        "    )\n",
        "    \n",
        "    img_bytes = img.numpy()\n",
        "    \n",
        "    img_format = b'jpeg'\n",
        "\n",
        "    \n",
        "    # Creating TFRecord\n",
        "    tf_record = tf.train.Example(\n",
        "        features = tf.train.Features(\n",
        "            feature = {\n",
        "                'image/height': dataset_util.int64_feature(h),\n",
        "                'image/width': dataset_util.int64_feature(w),\n",
        "                'image/filename': dataset_util.bytes_feature(filename),\n",
        "                'image/source_id': dataset_util.bytes_feature(source_id),\n",
        "                'image/encoded': dataset_util.bytes_feature(img_bytes),\n",
        "                'image/format': dataset_util.bytes_feature(img_format),\n",
        "            }\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    return tf_record"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUW2t_UQMml0"
      },
      "source": [
        "annot_path = \"/kaggle/working/workspace1/test-annotations\" \n",
        "os.makedirs(annot_path, exist_ok = True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ippfg-ZCMr5L"
      },
      "source": [
        "num_shards=1\n",
        "img_cnt = np.zeros(num_shards, dtype = int)\n",
        "\n",
        "filenames=os.listdir('../input/vinbigdata-chest-xray-abnormalities-detection/test')\n",
        "with contextlib2.ExitStack() as tf_record_close_stack:\n",
        "    output_tfrecords = tf_record_creation_util.open_sharded_output_tfrecords(\n",
        "        tf_record_close_stack, \n",
        "        annot_path, \n",
        "        num_shards\n",
        "    )\n",
        "    \n",
        "    for i in range(num_shards):\n",
        "    #df_shard = df[df[\"fold\"] == i]\n",
        "        xrays = set(filenames[:])\n",
        "\n",
        "        for xray in tqdm(xrays):\n",
        "            #df_image = df_shard[df_shard[\"image_id\"] == xray]\n",
        "\n",
        "            img_path = os.path.join('../input/vinbigdata-chest-xray-abnormalities-detection/test', xray)\n",
        "            tf_record = create_tf_record_test(img_path, 500)\n",
        "            output_tfrecords[i].write(tf_record.SerializeToString())\n",
        "            \n",
        "        img_cnt[i] += 1\n",
        "\n",
        "print(\"Converted {} images\".format(np.sum(img_cnt)))\n",
        "print(\"Images per shard: {}\".format(img_cnt))\n",
        "#print('DONE')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RU6jVtqFC0VE"
      },
      "source": [
        "#**TESTING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpMJ73FzC7PF"
      },
      "source": [
        "test_data=[]\n",
        "test_data.append('/content/gdrive/MyDrive/Tensorflow/workspace/test-annotations/test-annotations-00000-of-00001') \n",
        "test_data[:1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6xDOdTtDIht"
      },
      "source": [
        "for shard in test_data[:1]:\n",
        "    raw_dataset = tf.data.TFRecordDataset(shard)\n",
        "    print(raw_dataset)\n",
        "images=[]\n",
        "original_dimension=[]\n",
        "filenames=[]\n",
        "for raw_record in tqdm(raw_dataset.take(3000)): # Select one shard from the TFRecords dataset\n",
        "    example = tf.train.Example()\n",
        "    example.ParseFromString(raw_record.numpy())\n",
        "    img_encoded = example.features.feature['image/encoded'].bytes_list.value[0]\n",
        "    img = tf.io.decode_jpeg(img_encoded)\n",
        "    #print(img.shape)\n",
        "    img = cv2.cvtColor(img.numpy(), cv2.COLOR_GRAY2RGB)\n",
        "    img = img[tf.newaxis, ...]\n",
        "    img_width = example.features.feature['image/width'].int64_list.value[0]\n",
        "    img_height = example.features.feature['image/height'].int64_list.value[0]\n",
        "    filename = example.features.feature['image/filename'].bytes_list.value[0]\n",
        "    filename = str(filename,'utf-8')\n",
        "    filename=filename.split(\".\")[0]\n",
        "    filenames.append(filename)\n",
        "    original_dimension.append(tuple((img_width,img_height)))\n",
        "    images.append(img)\n",
        "#print(example)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbI985xTDsd0"
      },
      "source": [
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF8NkNZfEsd6"
      },
      "source": [
        "df = {'image_id':filenames,'PredictionString':predictions}\n",
        "df = pd.DataFrame(df)\n",
        "print(df)\n",
        "df = df.sort_values(by=['image_id'])\n",
        "df.to_csv('submission.csv',index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keXMHm7wM1MK"
      },
      "source": [
        "#**References**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VYcYvmaM6Jb"
      },
      "source": [
        "https://medium.com/analytics-vidhya/training-an-object-detection-model-with-tensorflow-api-using-google-colab-4f9a688d5e8b\n",
        "\n",
        "https://medium.com/swlh/tensorflow-2-object-detection-api-with-google-colab-b2af171e81cc\n",
        "\n",
        "https://www.youtube.com/watch?v=COlbP62-B-U&list=PLQVvvaa0QuDcNK5GeCQnxYnSSaar2tpku\n",
        "\n",
        "https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html\n",
        "\n",
        "https://www.kaggle.com/bhallaakshit/eda-and-preprocessing-for-tf2-object-detection\n",
        "\n",
        "https://www.kaggle.com/bhallaakshit/dicom-training-prediction-and-evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pk5RINLiM4wJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}